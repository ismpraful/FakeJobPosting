{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":171,"outputs":[{"output_type":"stream","text":"/kaggle/input/real-or-fake-fake-jobposting-prediction/fake_job_postings.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Reading Data in the dataframe\ndf_initial = pd.read_csv(r'/kaggle/input/real-or-fake-fake-jobposting-prediction/fake_job_postings.csv')\n\ndf_initial.head()","execution_count":172,"outputs":[{"output_type":"execute_result","execution_count":172,"data":{"text/plain":"   job_id                                      title            location  \\\n0       1                           Marketing Intern    US, NY, New York   \n1       2  Customer Service - Cloud Video Production      NZ, , Auckland   \n2       3    Commissioning Machinery Assistant (CMA)       US, IA, Wever   \n3       4          Account Executive - Washington DC  US, DC, Washington   \n4       5                        Bill Review Manager  US, FL, Fort Worth   \n\n  department salary_range                                    company_profile  \\\n0  Marketing          NaN  We're Food52, and we've created a groundbreaki...   \n1    Success          NaN  90 Seconds, the worlds Cloud Video Production ...   \n2        NaN          NaN  Valor Services provides Workforce Solutions th...   \n3      Sales          NaN  Our passion for improving quality of life thro...   \n4        NaN          NaN  SpotSource Solutions LLC is a Global Human Cap...   \n\n                                         description  \\\n0  Food52, a fast-growing, James Beard Award-winn...   \n1  Organised - Focused - Vibrant - Awesome!Do you...   \n2  Our client, located in Houston, is actively se...   \n3  THE COMPANY: ESRI – Environmental Systems Rese...   \n4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n\n                                        requirements  \\\n0  Experience with content management systems a m...   \n1  What we expect from you:Your key responsibilit...   \n2  Implement pre-commissioning and commissioning ...   \n3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n4  QUALIFICATIONS:RN license in the State of Texa...   \n\n                                            benefits  telecommuting  \\\n0                                                NaN              0   \n1  What you will get from usThrough being part of...              0   \n2                                                NaN              0   \n3  Our culture is anything but corporate—we have ...              0   \n4                              Full Benefits Offered              0   \n\n   has_company_logo  has_questions employment_type required_experience  \\\n0                 1              0           Other          Internship   \n1                 1              0       Full-time      Not Applicable   \n2                 1              0             NaN                 NaN   \n3                 1              0       Full-time    Mid-Senior level   \n4                 1              1       Full-time    Mid-Senior level   \n\n  required_education                   industry              function  \\\n0                NaN                        NaN             Marketing   \n1                NaN  Marketing and Advertising      Customer Service   \n2                NaN                        NaN                   NaN   \n3  Bachelor's Degree          Computer Software                 Sales   \n4  Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n\n   fraudulent  \n0           0  \n1           0  \n2           0  \n3           0  \n4           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>job_id</th>\n      <th>title</th>\n      <th>location</th>\n      <th>department</th>\n      <th>salary_range</th>\n      <th>company_profile</th>\n      <th>description</th>\n      <th>requirements</th>\n      <th>benefits</th>\n      <th>telecommuting</th>\n      <th>has_company_logo</th>\n      <th>has_questions</th>\n      <th>employment_type</th>\n      <th>required_experience</th>\n      <th>required_education</th>\n      <th>industry</th>\n      <th>function</th>\n      <th>fraudulent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Marketing Intern</td>\n      <td>US, NY, New York</td>\n      <td>Marketing</td>\n      <td>NaN</td>\n      <td>We're Food52, and we've created a groundbreaki...</td>\n      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n      <td>Experience with content management systems a m...</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Other</td>\n      <td>Internship</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Marketing</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Customer Service - Cloud Video Production</td>\n      <td>NZ, , Auckland</td>\n      <td>Success</td>\n      <td>NaN</td>\n      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n      <td>What we expect from you:Your key responsibilit...</td>\n      <td>What you will get from usThrough being part of...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Full-time</td>\n      <td>Not Applicable</td>\n      <td>NaN</td>\n      <td>Marketing and Advertising</td>\n      <td>Customer Service</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Commissioning Machinery Assistant (CMA)</td>\n      <td>US, IA, Wever</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Valor Services provides Workforce Solutions th...</td>\n      <td>Our client, located in Houston, is actively se...</td>\n      <td>Implement pre-commissioning and commissioning ...</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Account Executive - Washington DC</td>\n      <td>US, DC, Washington</td>\n      <td>Sales</td>\n      <td>NaN</td>\n      <td>Our passion for improving quality of life thro...</td>\n      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n      <td>Our culture is anything but corporate—we have ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Full-time</td>\n      <td>Mid-Senior level</td>\n      <td>Bachelor's Degree</td>\n      <td>Computer Software</td>\n      <td>Sales</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Bill Review Manager</td>\n      <td>US, FL, Fort Worth</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n      <td>Full Benefits Offered</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Full-time</td>\n      <td>Mid-Senior level</td>\n      <td>Bachelor's Degree</td>\n      <td>Hospital &amp; Health Care</td>\n      <td>Health Care Provider</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Columns in dataset df_initial\ndf_initial.columns","execution_count":173,"outputs":[{"output_type":"execute_result","execution_count":173,"data":{"text/plain":"Index(['job_id', 'title', 'location', 'department', 'salary_range',\n       'company_profile', 'description', 'requirements', 'benefits',\n       'telecommuting', 'has_company_logo', 'has_questions', 'employment_type',\n       'required_experience', 'required_education', 'industry', 'function',\n       'fraudulent'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import roc_auc_score\n","execution_count":174,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating df with selected/important columns\ndf = df_initial[['title', 'location', 'company_profile', 'description', 'requirements', 'industry', 'fraudulent']]\n# Dropping rows having NaN values\ndf_new = df.dropna()\n\n# Columns to retain\nfeatures = ['title', 'location', 'company_profile', 'description', 'requirements', 'industry']\ntarget = ['fraudulent']\n\nX = df_new[features]\ny = df_new['fraudulent']\n\n# Spliting data into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 1)","execution_count":175,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining CounterVectorizer\n\ncount_vect = CountVectorizer(min_df=3, ngram_range=[1, 2]).fit(X_train['title']+' '+X_train['location']+' '+X_train['company_profile']+' '+X_train['description']+' '+X_train['requirements']+' '+X_train['industry'])\nX_train_count_vect = count_vect.transform(X_train['title']+' '+X_train['location']+' '+X_train['company_profile']+' '+X_train['description']+' '+X_train['requirements']+' '+X_train['industry'])\nX_test_count_vect = count_vect.transform(X_test['title']+' '+X_test['location']+' '+X_test['company_profile']+' '+X_test['description']+' '+X_test['requirements']+' '+X_test['industry'])\n","execution_count":176,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining TfidfVectorizer\n\ntfidf_vect = TfidfVectorizer(min_df=3, ngram_range=[1, 2]).fit(X_train['title']+' '+X_train['location']+' '+X_train['company_profile']+' '+X_train['description']+' '+X_train['requirements']+' '+X_train['industry'])\nX_train_tfidf_vect = tfidf_vect.transform(X_train['title']+' '+X_train['location']+' '+X_train['company_profile']+' '+X_train['description']+' '+X_train['requirements']+' '+X_train['industry'])\nX_test_tfidf_vect = tfidf_vect.transform(X_test['title']+' '+X_test['location']+' '+X_test['company_profile']+' '+X_test['description']+' '+X_test['requirements']+' '+X_test['industry'])\n","execution_count":177,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using LogisticRegression and CounterVectorizer for calculating roc_auc_score\n\nlr_cv_model = LogisticRegression(C=0.1, max_iter=500, random_state = 1).fit(X_train_count_vect, y_train)\ny_pred_lr_cv = lr_cv_model.predict(X_test_count_vect)\nscore_lr_cv = roc_auc_score(y_test, y_pred_lr_cv)\nprint(\"roc_auc_score using LogisticRegression and CounterVectorizer: \", score_lr_cv)\n\n# get the feature names as numpy array\nfeature_names = np.array(count_vect.get_feature_names())\n# Sort the coefficients from the model\nsorted_coef_index = lr_cv_model.coef_[0].argsort()\n# Find the 10 smallest and 10 largest coefficients\nprint('\\n\\nSmallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))","execution_count":178,"outputs":[{"output_type":"stream","text":"roc_auc_score using LogisticRegression and CounterVectorizer:  0.96\n\n\nSmallest Coefs:\n['we' 'is' 'based' 'it' 'are' 'an' 'you' 'staff' 'recruitment' 'for']\n\nLargest Coefs: \n['hotel' 'financing' 'engineering' 'controls' 'industry' 'accion' 'more'\n 'money' 'is to' 'tx']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using LogisticRegression and TfidfVectorizer for calculating roc_auc_score\n\nlr_tfidf_model = LogisticRegression(C=15, max_iter=500, random_state = 1).fit(X_train_tfidf_vect, y_train)\ny_pred_lr_tfidf = lr_tfidf_model.predict(X_test_tfidf_vect)\nscore_lr_tfidf = roc_auc_score(y_test, y_pred_lr_tfidf)\nprint(\"roc_auc_score using LogisticRegression and TfidfVectorizer: \", score_lr_tfidf)\n\n\n# get the feature names as numpy array\nfeature_names = np.array(tfidf_vect.get_feature_names())\n# Sort the coefficients from the model\nsorted_coef_index = lr_tfidf_model.coef_[0].argsort()\n# Find the 10 smallest and 10 largest coefficients\nprint('\\n\\nSmallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))\n","execution_count":179,"outputs":[{"output_type":"stream","text":"roc_auc_score using LogisticRegression and TfidfVectorizer:  0.94\n\n\nSmallest Coefs:\n['you' 'we' 'of' 'it' 'social' 're' 'is' 'are' 'be' 'web']\n\nLargest Coefs: \n['hotel' 'accion' 'engineering' 'controls' 'and' 'payroll' 'novation'\n 'aptitude staffing' 'financing' 'american secured']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using MultinomialNB and CounterVectorizer for calculating roc_auc_score\n\nmnb_cv_model = MultinomialNB(alpha=0.1).fit(X_train_count_vect, y_train)\ny_pred_mnb_cv = mnb_cv_model.predict(X_test_count_vect)\nscore_mnb_cv = roc_auc_score(y_test, y_pred_mnb_cv)\nprint(\"roc_auc_score using MultinomialNB and CounterVectorizer: \", score_mnb_cv)\n\n# get the feature names as numpy array\nfeature_names = np.array(count_vect.get_feature_names())\n# Sort the coefficients from the model\nsorted_coef_index = mnb_cv_model.coef_[0].argsort()\n# Find the 10 smallest and 10 largest coefficients\nprint('\\n\\nSmallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))","execution_count":180,"outputs":[{"output_type":"stream","text":"roc_auc_score using MultinomialNB and CounterVectorizer:  0.97\n\n\nSmallest Coefs:\n['looking for aurora' 'policies perform' 'policies on'\n 'policies objectives initiatives' 'policies objectives'\n 'policies load unload' 'policies load' 'policies including health'\n 'policies practices' 'policies including']\n\nLargest Coefs: \n['and' 'to' 'the' 'of' 'in' 'with' 'for' 'our' 'is' 'experience']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using MultinomialNB and TfidfVectorizer for calculating roc_auc_score\n\nmnb_tfidf_model = MultinomialNB(alpha=0.01).fit(X_train_tfidf_vect, y_train)\ny_pred_mnb_tfidf = mnb_tfidf_model.predict(X_test_tfidf_vect)\nscore_mnb_tfidf = roc_auc_score(y_test, y_pred_mnb_tfidf)\nprint(\"roc_auc_score using MultinomialNB and TfidfVectorizer: \", score_mnb_tfidf)\n\n\n# get the feature names as numpy array\nfeature_names = np.array(tfidf_vect.get_feature_names())\n# Sort the coefficients from the model\nsorted_coef_index = mnb_tfidf_model.coef_[0].argsort()\n# Find the 10 smallest and 10 largest coefficients\nprint('\\n\\nSmallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))\n","execution_count":181,"outputs":[{"output_type":"stream","text":"roc_auc_score using MultinomialNB and TfidfVectorizer:  0.97\n\n\nSmallest Coefs:\n['looking for aurora' 'policies perform' 'policies on'\n 'policies objectives initiatives' 'policies objectives'\n 'policies load unload' 'policies load' 'policies including health'\n 'policies practices' 'policies including']\n\nLargest Coefs: \n['and' 'to' 'the' 'of' 'in' 'with' 'for' 'oil' 'our' 'engineering']\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}